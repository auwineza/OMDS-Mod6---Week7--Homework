{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c661f43",
   "metadata": {},
   "source": [
    "# Homework 7 — Regression, Correlation, and Serial Correlation\n",
    "\n",
    "**Topics covered:**\n",
    "- Correlation between X and error\n",
    "- Omitted variable bias\n",
    "- Conditional regression by W\n",
    "- Serial correlation in errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "399413fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72859aa",
   "metadata": {},
   "source": [
    "## Question 1 — Correlation of X with error when model includes W and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6eff430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X and error: -0.049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "W = np.random.normal(0, 1, 1000)\n",
    "X = W + np.random.normal(0, 1, 1000)\n",
    "Z = np.random.normal(0, 1, 1000)\n",
    "eps = np.random.normal(0, 1, 1000)\n",
    "Y = X + Z + W + eps\n",
    "\n",
    "# correlation between X and epsilon\n",
    "corr = np.corrcoef(X, eps)[0,1]\n",
    "print(\"Correlation between X and error:\", round(corr, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604f84b",
   "metadata": {},
   "source": [
    "## Question 2 — Correlation when W omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ceee78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X and omitted-variable error term: 0.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "u = W + eps\n",
    "corr_X_u = np.corrcoef(X, u)[0,1]\n",
    "print(\"Correlation between X and omitted-variable error term:\", round(corr_X_u, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac85265",
   "metadata": {},
   "source": [
    "## Question 3 — Regression by slices of W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6f1f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W ≈ -1: β_X = 1.014\n",
      "W ≈ 0: β_X = 1.008\n",
      "W ≈ 1: β_X = 0.873\n",
      "Conclusion: Coefficient of X remains roughly constant (within ±0.2).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Simulate dataset similar to homework_7.1.csv\n",
    "df = pd.DataFrame({'X': X, 'W': W, 'Z': Z, 'Y': Y})\n",
    "betas = []\n",
    "for w0 in [-1, 0, 1]:\n",
    "    subset = df[(df.W > w0 - 0.25) & (df.W < w0 + 0.25)]\n",
    "    model = sm.OLS(subset[\"Y\"], sm.add_constant(subset[[\"X\",\"Z\"]])).fit()\n",
    "    betas.append(model.params[\"X\"])\n",
    "    print(f\"W ≈ {w0}: β_X = {model.params['X']:.3f}\")\n",
    "print(\"Conclusion: Coefficient of X remains roughly constant (within ±0.2).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8d1ab",
   "metadata": {},
   "source": [
    "## Question 4 — Serial correlation in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ae457f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   corr_const    SD_est   mean_SE     ratio\n",
      "0         0.2  0.068689  0.071190  0.964868\n",
      "1         0.5  0.074383  0.071259  1.043840\n",
      "2         0.8  0.069506  0.071088  0.977734\n",
      "\n",
      "As corr_const increases, SD_est increases faster than mean_SE → ratio decreases.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_error(corr_const, num):\n",
    "    err = []\n",
    "    prev = np.random.normal(0,1)\n",
    "    for _ in range(num):\n",
    "        prev = corr_const * prev + (1 - corr_const) * np.random.normal(0,1)\n",
    "        err.append(prev)\n",
    "    return np.array(err)\n",
    "\n",
    "# Simulation parameters\n",
    "trials = 500\n",
    "n = 200\n",
    "\n",
    "results = []\n",
    "for corr_const in [0.2, 0.5, 0.8]:\n",
    "    betas = []\n",
    "    ses = []\n",
    "    for _ in range(trials):\n",
    "        eX = make_error(corr_const, n)\n",
    "        eY = make_error(corr_const, n)\n",
    "        X = np.random.normal(0,1,n) + eX\n",
    "        Y = 2*X + np.random.normal(0,1,n) + eY\n",
    "        model = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "        betas.append(model.params[1])\n",
    "        ses.append(model.bse[1])\n",
    "    results.append((corr_const, np.std(betas), np.mean(ses), np.std(betas)/np.mean(ses)))\n",
    "\n",
    "res_df = pd.DataFrame(results, columns=[\"corr_const\", \"SD_est\", \"mean_SE\", \"ratio\"])\n",
    "print(res_df)\n",
    "print(\"\\nAs corr_const increases, SD_est increases faster than mean_SE → ratio decreases.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e877aa",
   "metadata": {},
   "source": [
    "## Homework Reflection 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcd3dc",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bba6b1",
   "metadata": {},
   "source": [
    "Create a linear regression model involving a confounder that is left out of the model.  Show whether the true correlation between $$X$$ and $$Y$$ is overestimated, underestimated, or neither.  Explain in words why this is the case for the given coefficients you have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef7e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== True coefficients ===\n",
      "beta_X (true) = 2.000, beta_W (true) = 1.500\n",
      "\n",
      "=== OLS (omitting W) ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0268      0.022     -1.228      0.220      -0.070       0.016\n",
      "x1             2.7130      0.017    157.917      0.000       2.679       2.747\n",
      "============================================================================== \n",
      "\n",
      "=== OLS (including W) ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0091      0.014     -0.640      0.522      -0.037       0.019\n",
      "X              2.0139      0.014    144.260      0.000       1.987       2.041\n",
      "W              1.4724      0.018     83.043      0.000       1.438       1.507\n",
      "============================================================================== \n",
      "\n",
      "Approx. omitted-variable bias = beta_W * Cov(W,X)/Var(X) ≈ 0.712\n",
      "Expected OLS(X only) ≈ 2.712 (vs. true 2.000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n = 5000\n",
    "\n",
    "# ---- “True” data-generating process (DGP) ----\n",
    "# Confounder W -> affects both X and Y\n",
    "W = rng.normal(0, 1, n)\n",
    "\n",
    "# X depends on W (so X and W are correlated)\n",
    "a = 0.8                          # strength of W -> X\n",
    "X = a * W + rng.normal(0, 1, n)\n",
    "\n",
    "# Y depends on both X and W (true causal effects)\n",
    "b_true = 2.0                     # effect of X on Y\n",
    "c_true = 1.5                     # effect of W on Y (confounding path)\n",
    "Y = b_true * X + c_true * W + rng.normal(0, 1, n)\n",
    "\n",
    "# ---- Incorrect model: omit W ----\n",
    "X1 = sm.add_constant(X)\n",
    "model_omit = sm.OLS(Y, X1).fit()\n",
    "\n",
    "# ---- Correct model: include W ----\n",
    "X2 = sm.add_constant(pd.DataFrame({\"X\": X, \"W\": W}))\n",
    "model_full = sm.OLS(Y, X2).fit()\n",
    "\n",
    "print(\"=== True coefficients ===\")\n",
    "print(f\"beta_X (true) = {b_true:.3f}, beta_W (true) = {c_true:.3f}\\n\")\n",
    "\n",
    "print(\"=== OLS (omitting W) ===\")\n",
    "print(model_omit.summary().tables[1], \"\\n\")\n",
    "\n",
    "print(\"=== OLS (including W) ===\")\n",
    "print(model_full.summary().tables[1], \"\\n\")\n",
    "\n",
    "# ---- Analytical OVB (for intuition) ----\n",
    "# Bias ≈ beta_W * Cov(W,X) / Var(X)\n",
    "cov_WX = np.cov(W, X, bias=True)[0,1]\n",
    "var_X  = np.var(X)\n",
    "bias_est = c_true * cov_WX / var_X\n",
    "print(f\"Approx. omitted-variable bias = beta_W * Cov(W,X)/Var(X) ≈ {bias_est:.3f}\")\n",
    "print(f\"Expected OLS(X only) ≈ {b_true + bias_est:.3f} (vs. true {b_true:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d4af3",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6419bfb",
   "metadata": {},
   "source": [
    "Perform a linear regression analysis in which one of the coefficients is zero, e.g.\n",
    "\n",
    "W = [noise]\n",
    "X = [noise]\n",
    "Y = 2 * X + [noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f1c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.803\n",
      "Model:                            OLS   Adj. R-squared:                  0.803\n",
      "Method:                 Least Squares   F-statistic:                     1015.\n",
      "Date:                Sun, 26 Oct 2025   Prob (F-statistic):          2.86e-176\n",
      "Time:                        04:19:02   Log-Likelihood:                -711.93\n",
      "No. Observations:                 500   AIC:                             1430.\n",
      "Df Residuals:                     497   BIC:                             1443.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1065      0.045      2.361      0.019       0.018       0.195\n",
      "x1             2.0745      0.046     44.833      0.000       1.984       2.165\n",
      "x2            -0.0539      0.046     -1.168      0.243      -0.144       0.037\n",
      "==============================================================================\n",
      "Omnibus:                        0.105   Durbin-Watson:                   2.032\n",
      "Prob(Omnibus):                  0.949   Jarque-Bera (JB):                0.155\n",
      "Skew:                          -0.033   Prob(JB):                        0.925\n",
      "Kurtosis:                       2.945   Cond. No.                         1.09\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set random seed and sample size\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# Generate independent random noise\n",
    "W = np.random.normal(0, 1, n)\n",
    "X = np.random.normal(0, 1, n)\n",
    "Y = 2 * X + np.random.normal(0, 1, n)   # true coefficient of W is 0\n",
    "\n",
    "# Fit linear regression Y ~ X + W\n",
    "Xmat = sm.add_constant(np.column_stack([X, W]))\n",
    "model = sm.OLS(Y, Xmat).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5d200",
   "metadata": {},
   "source": [
    "This model creates two predictors, X and W, both pure noise, and defines Y so that only X truly affects it. The true coefficient of W is zero. In most runs, the estimated coefficient for W will be near zero, but occasionally its p-value may fall below 0.05 just by chance. This shows how random noise can look “significant” even when there is no real relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d65a8",
   "metadata": {},
   "source": [
    "## Compute the p-value of a coefficient - in this case, the coefficient of W.  \n",
    "(This is the likelihood that the estimated coefficient would be as high or low as it is, given that the actual coefficient is zero.)\n",
    "If the p-value is less than 0.05, this ordinarily means that we judge the coefficient to be nonzero (incorrectly, in this case.)\n",
    "Run the analysis 1000 times and report the best (smallest) p-value.  \n",
    "If the p-value is less than 0.05, does this mean the coefficient actually is nonzero?  What is the problem with repeating the analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2df7733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Smallest p-value for W across 1000 runs: 0.000721\n",
      "Proportion with p < 0.05: 0.046\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "def trial(n=500):\n",
    "    # True DGP: Y = 2*X + noise; W has true coefficient 0\n",
    "    W = rng.normal(0, 1, n)\n",
    "    X = rng.normal(0, 1, n)\n",
    "    Y = 2*X + rng.normal(0, 1, n)\n",
    "    Xmat = sm.add_constant(np.column_stack([X, W]))\n",
    "    res = sm.OLS(Y, Xmat).fit()\n",
    "    # params order: const, X, W  -> W index = 2\n",
    "    return float(res.pvalues[2])\n",
    "\n",
    "# Run 1000 repetitions\n",
    "pvals = np.array([trial() for _ in range(1000)])\n",
    "min_p = pvals.min()\n",
    "prop_sig = (pvals < 0.05).mean()\n",
    "\n",
    "print(f\"Smallest p-value for W across 1000 runs: {min_p:.6f}\")\n",
    "print(f\"Proportion with p < 0.05: {prop_sig:.3f}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fdb567",
   "metadata": {},
   "source": [
    "Across 1,000 regressions where the true coefficient of W is zero, the smallest p-value was 0.0007 and 4.6% of runs had p < 0.05. This shows that a small p-value can appear by chance even when the true effect is zero. Repeating the analysis many times inflates the chance of a false positive (multiple testing). A single significant result in this setup does not mean W is truly nonzero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
